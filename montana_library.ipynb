{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Montana Library Project__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Questions\n",
    "\n",
    "\n",
    "- Would you include all suggested variants in the experiment (Connect, Learn, Help, Services)?\n",
    "    * No, I would either include only \"Help\" as it was the most popular in our anecdotal sample, or \"Help\" and \"Services\"  \n",
    "    _\n",
    "- What is the “business value” that performing this experiment would add within the broader strategy of the University?\n",
    "    * Right now, students might need help but are not aware that there is help available. Therefore, by making students aware through a more descriptive button, they will get the help they need, increasing their satisfaction and their learning experience. This is good for the university.  \n",
    "    _\n",
    "- Which main metric would you choose to measure the success of a variant and perform the experiment on?\n",
    "    * I would use the click-through-rate.  \n",
    "    _\n",
    "- Which additional metrics would you choose to track?\n",
    "    * Depends on the technical capabilities of the platform. Time spent on site might also be useful.  \n",
    "    _\n",
    "- How would you define the null and the alternative hypotheses?\n",
    "    * H0: There is no difference in CTR between the variations.\n",
    "    * HA: There is a difference in CTR between the variations.  \n",
    "    _\n",
    "- What threshold for statistical significance would you set?\n",
    "    * I would go with the standard 0.05, as there are no particular risks for either type of error in this case. The classic value of 0.05 balances the probability of both errors nicely.  \n",
    "    _\n",
    "- What is the minimum detectable effect effect (the smallest improvement you would care about) that you expect to detect?\n",
    "    * A 50% improvement in CTR for the interact button (so from 2% to 3%)  \n",
    "    _\n",
    "- Do you think this experiment would require a software engineering team to develop a custom platform, or could it be developed with external tools such as Google Optimize?\n",
    "    * No idea since I have no clue about Google Optimize or other software solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import .csv files\n",
    "v1_interact = pd.read_csv(R\"data\\csv\\v1_interact.csv\")\n",
    "v2_connect = pd.read_csv(R\"data\\csv\\v2_connect.csv\")\n",
    "v3_learn = pd.read_csv(R\"data\\csv\\v3_learn.csv\")\n",
    "v4_help = pd.read_csv(R\"data\\csv\\v4_help.csv\")\n",
    "v5_services = pd.read_csv(R\"data\\csv\\v5_services.csv\")\n",
    "\n",
    "# Append files into one dataframe\n",
    "data= []\n",
    "data.append(v1_interact)\n",
    "data.append(v2_connect)\n",
    "data.append(v3_learn)\n",
    "data.append(v4_help)\n",
    "data.append(v5_services)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get important metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            INTERACT   CONNECT     LEARN      HELP  SERVICES\n",
      "click         42.000    53.000    21.000    38.000    45.000\n",
      "no_click   10241.000  2689.000  2726.000  3142.000  2019.000\n",
      "ctr_value      0.004     0.019     0.008     0.012     0.022\n"
     ]
    }
   ],
   "source": [
    "# Define total views of page for each variation (taken from heatmaps in data folder)\n",
    "# Order from v1 to v5\n",
    "total_visits = [10283, 2742, 2747, 3180, 2064]\n",
    "\n",
    "# Get clicks and no_clicks  \n",
    "click = []\n",
    "no_click = []\n",
    "ctr_values =[]\n",
    "\n",
    "v_name = ['INTERACT', 'CONNECT', 'LEARN', 'HELP', 'SERVICES']\n",
    "v_nr=0\n",
    "\n",
    "for variation in data:\n",
    "    click.append(variation.loc[lambda df_ : df_['Name']== v_name[v_nr], 'No. clicks'].sum())\n",
    "    no_click.append(total_visits[v_nr] - click[v_nr])\n",
    "    ctr_values.append(round(click[v_nr] / total_visits[v_nr], 3))\n",
    "    v_nr+=1\n",
    "\n",
    "\n",
    "observed = pd.DataFrame([click, no_click, ctr_values],\n",
    "                           columns = v_name,\n",
    "                           index = [\"click\", \"no_click\", \"ctr_value\"])\n",
    "\n",
    "# Create contingency table\n",
    "cont_table = observed.drop('ctr_value', axis = 0)\n",
    "\n",
    "print(observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Questions\n",
    "\n",
    "- What was the click-through rate for each version?\n",
    "    * See \"observed\" df\n",
    "- Which version was the winner?\n",
    "    * V5 ('services') has the highest CTR (0.022) and can therefore be considered \"the winner\"\n",
    "- Do the results seem conclusive?\n",
    "    * Not at all because we didn't perform any statistical tests, so we can't evaluate how likely it is that we got these results due to chance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Chi-Square test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chi_square</th>\n",
       "      <th>p_value</th>\n",
       "      <th>df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>96.743235</td>\n",
       "      <td>4.852334e-20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chi_square       p_value  df\n",
       "value   96.743235  4.852334e-20   4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform test itself\n",
    "chisq, pvalue, df, expected = stats.chi2_contingency(cont_table)\n",
    "\n",
    "# Arrange results in df for easy access\n",
    "output = {'chi_square': chisq, 'p_value': pvalue, 'df': df}\n",
    "chi2_res_full = pd.DataFrame(data = output, index = ['value'])\n",
    "chi2_res_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for Chi-Square Test, returns df with results\n",
    "def chi_square(contingency_table):\n",
    "    chisq, pvalue, df, expected = stats.chi2_contingency(contingency_table)\n",
    "    output = {'chi_square': chisq, 'p_value': pvalue, 'df': df}\n",
    "    return pd.DataFrame(data = output, index = ['value'])\n",
    "\n",
    "# define temporary variables for the while loop\n",
    "tmp_chi2_res = chi2_res_full.copy()\n",
    "tmp_observed = observed.copy()\n",
    "tmp_pvalue = chi2_res_full.at['value', 'p_value']\n",
    "\n",
    "# when the p_value of the chi-square test is below our set alpha, the variation with the worst CTR is removed and the test is performed again \n",
    "# stops when the p_value is higher than alpha, or if only one variation is left\n",
    "alpha = 0.1\n",
    "\n",
    "while tmp_pvalue < alpha :\n",
    "    worst_variant = tmp_observed.loc['ctr_value',].idxmin()\n",
    "    tmp_observed = tmp_observed.drop(worst_variant, axis= 1)\n",
    "    tmp_chi2_res = chi_square(tmp_observed.loc[['click', 'no_click']])\n",
    "    tmp_pvalue = tmp_chi2_res.at['value', 'p_value']\n",
    "    if len(tmp_observed.columns) == 1:\n",
    "        break\n",
    "\n",
    "# save final versions in new variables for clarity\n",
    "best_variants = tmp_observed.copy()\n",
    "final_chi2_res = tmp_chi2_res.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation and Evaluation\n",
    "\n",
    "- The last remaining variants are \"Connect\" and \"Services\"\n",
    "- Considering the extremely low dropoff - und homepage-return rates of \"Services\", I conclude that it is the best variation and should be implemented with fairly high certainty of an improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CONNECT  SERVICES\n",
      "click        53.000    45.000\n",
      "no_click   2689.000  2019.000\n",
      "ctr_value     0.019     0.022\n"
     ]
    }
   ],
   "source": [
    "print(best_variants)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f32269641e17bf27d9ca909c2404938da1b1b2df6b9d3f5a88a1b877c863c5b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
